{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP213aCkaH7jDZuInhZPYOU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/huynhbaoking112/FOOTBALL_AI_ANALYTICS/blob/main/fooball_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPC48Owan7q4",
        "outputId": "ce727151-dfd9-4bc7-a18a-0cd38f4fff25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Oct 26 08:39:49 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   55C    P8              11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gdown inference-gpu supervision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKsLCITen_s1",
        "outputId": "88ae2083-28de-4102-fe5b-767b72792383"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.6/792.6 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.1/148.1 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.0/906.0 kB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.7/135.7 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m891.9/891.9 kB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.8/91.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.9/386.9 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.7/239.7 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.2/67.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.6/97.6 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m940.0/940.0 kB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.5/33.5 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m102.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.6/82.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.9/384.9 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.7/17.7 MB\u001b[0m \u001b[31m100.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m548.2/548.2 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.31.0 which is incompatible.\n",
            "pymc 5.16.2 requires rich>=13.7.1, but you have rich 13.5.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/roboflow/sports.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWvM-3-sp6WV",
        "outputId": "ec8828f2-9ee1-4358-ea16-cf1330885417"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sports (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y supervision && pip install -q supervision>=0.23.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UercGLZuIAX",
        "outputId": "f967e1d4-38a3-4a76-d752-ccd77d7ae337"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: supervision 0.22.0\n",
            "Uninstalling supervision-0.22.0:\n",
            "  Successfully uninstalled supervision-0.22.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "inference-gpu 0.24.0 requires supervision<=0.22.0,>=0.21.0, but you have supervision 0.24.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown -O \"0bfacc_0.mp4\" \"https://drive.google.com/uc?id=12TqauVZ9tLAv8kWxTTBFWtgt2hNQ4_ZF\"\n",
        "!gdown -O \"2e57b9_0.mp4\" \"https://drive.google.com/uc?id=19PGw55V8aA6GZu5-Aac5_9mCy3fNxmEf\"\n",
        "!gdown -O \"08fd33_0.mp4\" \"https://drive.google.com/uc?id=1OG8K6wqUw9t7lp9ms1M48DxRhwTYciK-\"\n",
        "!gdown -O \"573e61_0.mp4\" \"https://drive.google.com/uc?id=1yYPKuXbHsCxqjA9G-S6aeR2Kcnos8RPU\"\n",
        "!gdown -O \"121364_0.mp4\" \"https://drive.google.com/uc?id=1vVwjW1dE1drIdd4ZSILfbCGPD4weoNiu\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7cN01d_vCqH",
        "outputId": "ca7df1fa-f830-49cd-89a0-d89da47c8300"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=12TqauVZ9tLAv8kWxTTBFWtgt2hNQ4_ZF\n",
            "To: /content/0bfacc_0.mp4\n",
            "100% 19.9M/19.9M [00:00<00:00, 22.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19PGw55V8aA6GZu5-Aac5_9mCy3fNxmEf\n",
            "To: /content/2e57b9_0.mp4\n",
            "100% 21.1M/21.1M [00:00<00:00, 28.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1OG8K6wqUw9t7lp9ms1M48DxRhwTYciK-\n",
            "To: /content/08fd33_0.mp4\n",
            "100% 19.9M/19.9M [00:00<00:00, 25.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1yYPKuXbHsCxqjA9G-S6aeR2Kcnos8RPU\n",
            "To: /content/573e61_0.mp4\n",
            "100% 18.9M/18.9M [00:00<00:00, 32.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1vVwjW1dE1drIdd4ZSILfbCGPD4weoNiu\n",
            "To: /content/121364_0.mp4\n",
            "100% 17.2M/17.2M [00:00<00:00, 27.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"ONNXRUNTIME_EXECUTION_PROVIDERS\"] = \"[CUDAExecutionProvider]\""
      ],
      "metadata": {
        "id": "PZ9uYooRvt8f"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from inference import get_model\n",
        "from google.colab import userdata\n",
        "\n",
        "ROBO_FLOW_API = userdata.get(\"ROBO_FLOW_API\")\n",
        "PLAYER_DETERCTION_MODEL_ID = \"football-players-detection-3zvbc/12\"\n",
        "PLAYER_DETECTION_MODEL = get_model(model_id = PLAYER_DETERCTION_MODEL_ID, api_key=ROBO_FLOW_API)"
      ],
      "metadata": {
        "id": "CbLSMotBwen8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import supervision as sv\n",
        "SOURCE_VIDEO_PATH = \"/content/121364_0.mp4\"\n",
        "TARGET_VIDEO_PATH = '/content/121364_0_result_1.mp4'\n",
        "\n",
        "box_annotator = sv.BoxAnnotator(\n",
        "    color = sv.ColorPalette.from_hex(['#FF8C00','#00BFFF', '#FF1493', '#FFD700']),\n",
        "    thickness = 2\n",
        ")\n",
        "label_annotator = sv.LabelAnnotator(\n",
        "    color = sv.ColorPalette.from_hex(['#FF8C00', '#00BFFF', '#FF1493','#FFD700']),\n",
        "    text_color = sv.Color.from_hex('#000000')\n",
        ")\n",
        "\n",
        "video_info = sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n",
        "video_sink = sv.VideoSink(TARGET_VIDEO_PATH, video_info = video_info)\n",
        "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "\n",
        "with video_sink:\n",
        "    for frame in tqdm(frame_generator, total = video_info.total_frames):\n",
        "\n",
        "          result = PLAYER_DETECTION_MODEL.infer(frame, confidence = 0.3)[0]\n",
        "          detections = sv.Detections.from_inference(result)\n",
        "\n",
        "\n",
        "          labels = [\n",
        "              f\"{class_name} {confidence:.2f}\"\n",
        "              for class_name, confidence\n",
        "              in zip(detections[\"class_name\"], detections.confidence)\n",
        "          ]\n",
        "\n",
        "          annotated_frame = frame.copy()\n",
        "          annotated_frame = box_annotator.annotate(annotated_frame, detections)\n",
        "          annotated_frame = label_annotator.annotate(annotated_frame, detections, labels = labels)\n",
        "          video_sink.write_frame(annotated_frame)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "xu7myT8ywmEh",
        "outputId": "9c33cffb-d894-4d42-ba3d-d3a90a3beb1a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 95/750 [16:41<1:55:05, 10.54s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-74af1c908258>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideo_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m           \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPLAYER_DETECTION_MODEL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfidence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m           \u001b[0mdetections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDetections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/inference/core/models/object_detection_base.py\u001b[0m in \u001b[0;36minfer\u001b[0;34m(self, image, class_agnostic_nms, confidence, disable_preproc_auto_orient, disable_preproc_contrast, disable_preproc_grayscale, disable_preproc_static_crop, iou_threshold, fix_batch_size, max_candidates, max_detections, return_image_dims, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mbatching\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0menabled\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \"\"\"\n\u001b[0;32m---> 76\u001b[0;31m         return super().infer(\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mclass_agnostic_nms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_agnostic_nms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/inference/core/models/roboflow.py\u001b[0m in \u001b[0;36minfer\u001b[0;34m(self, image, **kwargs)\u001b[0m\n\u001b[1;32m    626\u001b[0m         \u001b[0mmax_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMAX_BATCH_SIZE\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatching_enabled\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_elements\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_batch_size\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m         logger.debug(\n\u001b[1;32m    630\u001b[0m             \u001b[0;34mf\"Inference will be executed in batches, as there is {input_elements} input elements and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/inference/usage_tracking/collector.py\u001b[0m in \u001b[0;36msync_wrapper\u001b[0;34m(usage_fps, usage_api_key, usage_workflow_id, usage_workflow_preview, usage_inference_test_run, *args, **kwargs)\u001b[0m\n\u001b[1;32m    621\u001b[0m                 )\n\u001b[1;32m    622\u001b[0m             )\n\u001b[0;32m--> 623\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/inference/core/models/base.py\u001b[0m in \u001b[0;36minfer\u001b[0;34m(self, image, **kwargs)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;34mf\"Preprocessed input shape: {getattr(preproc_image, 'shape', None)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         )\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mpredicted_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreproc_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mpostprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturned_metadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/inference/models/yolov8/yolov8_object_detection.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, img_in, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNumPy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mrepresenting\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincluding\u001b[0m \u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfidence\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mconfidence\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \"\"\"\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimg_in\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0moutput_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_meta\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_feed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPFail\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_fallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yXtHIOz0-Bbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Lấy thông tin video\n",
        "python\n",
        "Sao chép mã\n",
        "video_info = sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n",
        "sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH): Đây là phương thức để tạo một đối tượng VideoInfo, chứa các thông tin về video như độ phân giải, tổng số khung hình, thời gian, v.v. Tham số SOURCE_VIDEO_PATH là đường dẫn đến file video mà bạn muốn xử lý.\n",
        "2. Khởi tạo VideoSink\n",
        "python\n",
        "Sao chép mã\n",
        "video_sink = sv.VideoSink(TARGET_VIDEO_PATH, video_info=video_info)\n",
        "sv.VideoSink: Đây là một lớp cho phép ghi các khung hình đã được xử lý vào một file video mới.\n",
        "TARGET_VIDEO_PATH: Là đường dẫn nơi file video kết quả sẽ được lưu.\n",
        "video_info=video_info: Tham số này cung cấp thông tin về video (như độ phân giải) để video mới được tạo ra có cùng thông số.\n",
        "3. Tạo generator để lấy khung hình video\n",
        "python\n",
        "Sao chép mã\n",
        "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "sv.get_video_frames_generator(SOURCE_VIDEO_PATH): Phương thức này tạo một generator cho phép bạn lặp qua từng khung hình của video nguồn. Khi bạn gọi next(frame_generator), nó sẽ trả về khung hình tiếp theo trong video.\n",
        "4. Ghi và xử lý video\n",
        "python\n",
        "Sao chép mã\n",
        "with video_sink:\n",
        "    for frame in tqdm(frame_generator, total=video_info.total_frames):\n",
        "with video_sink:: Mở video_sink để chuẩn bị ghi các khung hình. Đoạn mã bên trong khối with sẽ ghi khung hình vào file video kết quả.\n",
        "for frame in tqdm(frame_generator, total=video_info.total_frames):: Sử dụng tqdm để hiển thị thanh tiến trình trong khi lặp qua các khung hình video. total=video_info.total_frames giúp xác định tổng số khung hình để tính toán tiến trình.\n",
        "5. Suy diễn và gán nhãn cho khung hình\n",
        "python\n",
        "Sao chép mã\n",
        "result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
        "detections = sv.Detections.from_inference(result)\n",
        "PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]: Gọi mô hình phát hiện cầu thủ để suy diễn trên khung hình hiện tại. Tham số confidence=0.3 chỉ định ngưỡng độ tin cậy, nghĩa là chỉ các phát hiện có độ tin cậy trên 30% mới được xem là hợp lệ.\n",
        "sv.Detections.from_inference(result): Chuyển đổi kết quả suy diễn thành một đối tượng Detections, giúp dễ dàng xử lý và gán nhãn cho các đối tượng phát hiện.\n",
        "6. Tạo nhãn cho các phát hiện\n",
        "python\n",
        "Sao chép mã\n",
        "labels = [\n",
        "    f\"{class_name} {confidence:.2f}\"\n",
        "    for class_name, confidence\n",
        "    in zip(detections[\"class_name\"], detections.confidence)\n",
        "]\n",
        "labels = [...]: Tạo một danh sách các nhãn cho từng phát hiện. Mỗi nhãn bao gồm tên lớp (class_name) và độ tin cậy (confidence) được định dạng thành chuỗi với hai chữ số thập phân.\n",
        "7. Ghi khung hình đã được gán nhãn vào video\n",
        "python\n",
        "Sao chép mã\n",
        "annotated_frame = frame.copy()\n",
        "annotated_frame = box_annotator.annotate(annotated_frame, detections)\n",
        "annotated_frame = label_annotator.annotate(annotated_frame, detections, labels=labels)\n",
        "video_sink.write_frame(annotated_frame)\n",
        "annotated_frame = frame.copy(): Tạo một bản sao của khung hình gốc để thực hiện các thay đổi mà không làm ảnh hưởng đến khung hình gốc.\n",
        "box_annotator.annotate(...): Gán nhãn cho các đối tượng phát hiện bằng cách vẽ hộp bao quanh chúng trên khung hình.\n",
        "label_annotator.annotate(...): Thêm các nhãn (bao gồm tên lớp và độ tin cậy) vào khung hình đã được gán nhãn.\n",
        "video_sink.write_frame(annotated_frame): Ghi khung hình đã được gán nhãn vào video kết quả.\n",
        "Tóm tắt\n",
        "Tóm lại, đoạn mã này thực hiện các bước sau:\n",
        "\n",
        "Đọc thông tin video từ file.\n",
        "Tạo một video sink để ghi video kết quả.\n",
        "Lấy từng khung hình từ video gốc.\n",
        "Sử dụng mô hình phát hiện cầu thủ để suy diễn trên từng khung hình.\n",
        "Gán nhãn cho các phát hiện.\n",
        "Ghi khung hình đã được gán nhãn vào file video mới.\n",
        "Kết quả là một video mới có các cầu thủ được đánh dấu bằng hộp bao quanh và nhãn tương ứng."
      ],
      "metadata": {
        "id": "dmgEOCbf8rSH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import supervision as sv\n",
        "\n",
        "SOURCE_VIDEO_PATH = \"/content/121364_0.mp4\"\n",
        "BALL_ID = 0\n",
        "\n",
        "ellipse_annotator = sv.EllipseAnnotator(\n",
        "    color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),\n",
        "    thickness=2\n",
        ")\n",
        "triangle_annotator = sv.TriangleAnnotator(\n",
        "    color=sv.Color.from_hex('#FFD700'),\n",
        "    base=25,\n",
        "    height=21,\n",
        "    outline_thickness=1\n",
        ")\n",
        "\n",
        "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "frame = next(frame_generator)\n",
        "\n",
        "result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
        "detections = sv.Detections.from_inference(result)\n",
        "\n",
        "ball_detections = detections[detections.class_id == BALL_ID]\n",
        "ball_detections.xyxy = sv.pad_boxes(xyxy=ball_detections.xyxy, px=10)\n",
        "\n",
        "all_detections = detections[detections.class_id != BALL_ID]\n",
        "all_detections = all_detections.with_nms(threshold=0.5, class_agnostic=True)\n",
        "all_detections.class_id -= 1\n",
        "\n",
        "annotated_frame = frame.copy()\n",
        "annotated_frame = ellipse_annotator.annotate(\n",
        "    scene=annotated_frame,\n",
        "    detections=all_detections)\n",
        "annotated_frame = triangle_annotator.annotate(\n",
        "    scene=annotated_frame,\n",
        "    detections=ball_detections)\n",
        "\n",
        "sv.plot_image(annotated_frame)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "PTdNkppM0x4C",
        "outputId": "c65e962b-1d0d-4483-e765-584b79376603"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'supervision'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d52d09944e6d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msupervision\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mSOURCE_VIDEO_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/121364_0.mp4\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mBALL_ID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'supervision'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# CHÚ THÍCH\n",
        "detections = {\n",
        "    'class_id': [0, 1, 2],  # Các ID lớp cho mỗi phát hiện\n",
        "    'confidence': [0.95, 0.87, 0.76],  # Độ tin cậy cho mỗi phát [hiện](https://)\n",
        "    'xyxy': [[50, 30, 200, 180], [30, 40, 100, 120], [120, 50, 220, 200]],  # Tọa độ hộp bao\n",
        "}\n"
      ],
      "metadata": {
        "id": "lIWD5PaJDbis"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import supervision as sv\n",
        "\n",
        "SOURCE_VIDEO_PATH = \"/content/121364_0.mp4\"\n",
        "BALL_ID = 0\n",
        "\n",
        "ellipse_annotator = sv.EllipseAnnotator(\n",
        "    color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),\n",
        "    thickness=2\n",
        ")\n",
        "label_annotator = sv.LabelAnnotator(\n",
        "    color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),\n",
        "    text_color=sv.Color.from_hex('#000000'),\n",
        "    text_position=sv.Position.BOTTOM_CENTER\n",
        ")\n",
        "triangle_annotator = sv.TriangleAnnotator(\n",
        "    color=sv.Color.from_hex('#FFD700'),\n",
        "    base=25,\n",
        "    height=21,\n",
        "    outline_thickness=1\n",
        ")\n",
        "\n",
        "tracker = sv.ByteTrack()\n",
        "tracker.reset()\n",
        "\n",
        "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "frame = next(frame_generator)\n",
        "\n",
        "result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
        "detections = sv.Detections.from_inference(result)\n",
        "\n",
        "ball_detections = detections[detections.class_id == BALL_ID]\n",
        "ball_detections.xyxy = sv.pad_boxes(xyxy=ball_detections.xyxy, px=10)\n",
        "\n",
        "all_detections = detections[detections.class_id != BALL_ID]\n",
        "all_detections = all_detections.with_nms(threshold=0.5, class_agnostic=True)\n",
        "all_detections.class_id -= 1\n",
        "all_detections = tracker.update_with_detections(detections=all_detections)\n",
        "\n",
        "labels = [\n",
        "    f\"#{tracker_id}\"\n",
        "    for tracker_id\n",
        "    in all_detections.tracker_id\n",
        "]\n",
        "\n",
        "annotated_frame = frame.copy()\n",
        "annotated_frame = ellipse_annotator.annotate(\n",
        "    scene=annotated_frame,\n",
        "    detections=all_detections)\n",
        "annotated_frame = label_annotator.annotate(\n",
        "    scene=annotated_frame,\n",
        "    detections=all_detections,\n",
        "    labels=labels)\n",
        "annotated_frame = triangle_annotator.annotate(\n",
        "    scene=annotated_frame,\n",
        "    detections=ball_detections)\n",
        "\n",
        "sv.plot_image(annotated_frame)"
      ],
      "metadata": {
        "id": "vjQ5tYgG-She"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "SOURCE_VIDEO_PATH = \"/content/121364_0.mp4\"\n",
        "PLAYER_ID = 2\n",
        "STRIDE = 30\n",
        "\n",
        "frame_generator = sv.get_video_frames_generator(\n",
        "    source_path=SOURCE_VIDEO_PATH, stride=STRIDE)\n",
        "\n",
        "crops = []\n",
        "for frame in tqdm(frame_generator, desc='collecting crops'):\n",
        "    result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
        "    detections = sv.Detections.from_inference(result)\n",
        "    detections = detections.with_nms(threshold=0.5, class_agnostic=True)\n",
        "    detections = detections[detections.class_id == PLAYER_ID]\n",
        "    players_crops = [sv.crop_image(frame, xyxy) for xyxy in detections.xyxy]\n",
        "    crops += players_crops"
      ],
      "metadata": {
        "id": "3rcd2364GanJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoProcessor, SiglipVisionModel\n",
        "\n",
        "SIGLIP_MODEL_PATH = 'google/siglip-base-patch16-224'\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "EMBEDDINGS_MODEL = SiglipVisionModel.from_pretrained(SIGLIP_MODEL_PATH).to(DEVICE)\n",
        "EMBEDDINGS_PROCESSOR = AutoProcessor.from_pretrained(SIGLIP_MODEL_PATH)"
      ],
      "metadata": {
        "id": "TAyV-J2FIepP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from more_itertools import chunked\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "crops = [sv.cv2_to_pillow(crop) for crop in crops]\n",
        "batches = chunked(crops, BATCH_SIZE)\n",
        "data = []\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(batches, desc='embedding extraction'):\n",
        "        inputs = EMBEDDINGS_PROCESSOR(images=batch, return_tensors=\"pt\").to(DEVICE)\n",
        "        outputs = EMBEDDINGS_MODEL(**inputs)\n",
        "        embeddings = torch.mean(outputs.last_hidden_state, dim=1).cpu().numpy()\n",
        "        data.append(embeddings)\n",
        "\n",
        "data = np.concatenate(data)"
      ],
      "metadata": {
        "id": "wF7aJrlbR-v0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}